{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE-CIC-IDS 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"dnn8-sgd-autoencodershape\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Xetrov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Xetrov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Xetrov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Xetrov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Xetrov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Xetrov\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob, time, os\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = \"C:/Users/Xetrov/Desktop/SciFair20/Code/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = pd.read_csv(NOTEBOOK_PATH + \"IDS2017/x_scaled_powertransform.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df_enc = pd.read_csv(NOTEBOOK_PATH + \"IDS2017/y_all_binary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valtest, y_train, y_valtest = train_test_split(x_scaled, y_df_enc, test_size = 0.4, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_test, y_val, y_test = train_test_split(x_valtest, y_valtest, test_size = 0.5, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x_train\n",
    "del y_train\n",
    "del x_valtest \n",
    "del y_valtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_res = pd.read_csv(NOTEBOOK_PATH + \"IDS2017/x_adasyn_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_res = pd.read_csv(NOTEBOOK_PATH + \"IDS2017/y_adasyn_binary.csv\")['IsAttack']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, InputLayer\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDenseBlock(model, units, **params):\n",
    "    model.add(Dense(units=units, activation=params['hidden_activation'], input_dim=x_train_res.shape[1]))\n",
    "    if params['batch_normalization']: model.add(BatchNormalization())\n",
    "    if params['dropout_rate'] > 0: model.add(Dropout(params['dropout_rate']))\n",
    "\n",
    "def createModel(**in_params):\n",
    "    \"\"\"\n",
    "    Supported parameters:\n",
    "    batch_normalization - True or False\n",
    "    dropout_rate - 0 to 1\n",
    "    num_units - integer\n",
    "    learning_rate - float\n",
    "    activation_function - string\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Set default values\n",
    "    params = {\n",
    "        'batch_normalization': True,\n",
    "        'dropout_rate': 0,\n",
    "        'num_layers': 6,\n",
    "        'num_units': 128,\n",
    "        'learning_rate': 0.001,\n",
    "        'hidden_activation': 'relu',\n",
    "        'final_activation': 'sigmoid'\n",
    "    }\n",
    "    \n",
    "    # Replace defaults with specified parameters\n",
    "    for param in in_params:\n",
    "        params[param] = in_params[param]    \n",
    "    \n",
    "    # InputLayer causes serialization issues\n",
    "#     model.add( InputLayer(input_shape = (x_train.shape[1],) ) )\n",
    "    \n",
    "#     for i in range(params['num_layers']):\n",
    "#         addDenseBlock(model, params['num_units'], **params)\n",
    "\n",
    "    addDenseBlock(model, 256, **params)\n",
    "    addDenseBlock(model, 128, **params)\n",
    "    addDenseBlock(model, 64, **params)\n",
    "    addDenseBlock(model, 32, **params)\n",
    "    addDenseBlock(model, 64, **params)\n",
    "    addDenseBlock(model, 128, **params)\n",
    "    addDenseBlock(model, 256, **params)\n",
    "\n",
    "    model.add(Dense(units=1, activation=params['final_activation']))\n",
    "\n",
    "    optim = SGD(lr=0.001, nesterov=True)\n",
    "#     optim = Adam(lr=params['learning_rate'])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    \n",
    "#     print(params)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def timestamp():\n",
    "    return time.strftime(\"%m-%d-%Y, %I%M%p\")\n",
    "\n",
    "csv_callback = CSVLogger(NOTEBOOK_PATH + 'Loss Logs/%s (%s)' % (model_id, timestamp()), append=True)\n",
    "early_stop = EarlyStopping(monitor = 'val_loss', min_delta=0.0001, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created C:/Users/Xetrov/Desktop/SciFair20/Code/Models/dnn8-sgd-autoencodershape/\n"
     ]
    }
   ],
   "source": [
    "savedir = NOTEBOOK_PATH + \"Models/%s/\" % model_id\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "    print(\"Created \" + savedir)\n",
    "else:\n",
    "    print(\"Using \" + savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure a GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "trainEpochs = 700\n",
    "\n",
    "parameters = {'batch_size': 1000, 'batch_normalization':True,'dropout_rate':0, 'final_activation':'sigmoid'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn8-sgd-autoencodershape\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               17664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 108,321\n",
      "Trainable params: 106,465\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n",
      "Train on 2727615 samples, validate on 566149 samples\n",
      "Epoch 1/700\n",
      " - 34s - loss: 0.1214 - acc: 0.9583 - val_loss: 0.0723 - val_acc: 0.9746\n",
      "Epoch 2/700\n",
      " - 32s - loss: 0.0624 - acc: 0.9805 - val_loss: 0.0554 - val_acc: 0.9797\n",
      "Epoch 3/700\n",
      " - 32s - loss: 0.0503 - acc: 0.9846 - val_loss: 0.0510 - val_acc: 0.9809\n",
      "Epoch 4/700\n",
      " - 32s - loss: 0.0441 - acc: 0.9865 - val_loss: 0.0493 - val_acc: 0.9815\n",
      "Epoch 5/700\n",
      " - 32s - loss: 0.0396 - acc: 0.9879 - val_loss: 0.0392 - val_acc: 0.9840\n",
      "Epoch 6/700\n",
      " - 32s - loss: 0.0362 - acc: 0.9890 - val_loss: 0.0351 - val_acc: 0.9881\n",
      "Epoch 7/700\n",
      " - 32s - loss: 0.0335 - acc: 0.9900 - val_loss: 0.0376 - val_acc: 0.9862\n",
      "Epoch 8/700\n",
      " - 32s - loss: 0.0311 - acc: 0.9909 - val_loss: 0.0267 - val_acc: 0.9931\n",
      "Epoch 9/700\n",
      " - 32s - loss: 0.0293 - acc: 0.9916 - val_loss: 0.0319 - val_acc: 0.9898\n",
      "Epoch 10/700\n",
      " - 32s - loss: 0.0279 - acc: 0.9921 - val_loss: 0.0353 - val_acc: 0.9866\n",
      "Epoch 11/700\n",
      " - 32s - loss: 0.0268 - acc: 0.9924 - val_loss: 0.0311 - val_acc: 0.9905\n",
      "Epoch 12/700\n",
      " - 32s - loss: 0.0260 - acc: 0.9927 - val_loss: 0.0279 - val_acc: 0.9912\n",
      "Epoch 13/700\n",
      " - 32s - loss: 0.0252 - acc: 0.9930 - val_loss: 0.0321 - val_acc: 0.9907\n",
      "Epoch 14/700\n",
      " - 32s - loss: 0.0244 - acc: 0.9933 - val_loss: 0.0291 - val_acc: 0.9909\n",
      "Epoch 15/700\n",
      " - 32s - loss: 0.0238 - acc: 0.9935 - val_loss: 0.0273 - val_acc: 0.9912\n",
      "Epoch 16/700\n",
      " - 32s - loss: 0.0234 - acc: 0.9936 - val_loss: 0.0256 - val_acc: 0.9926\n",
      "Epoch 17/700\n",
      " - 32s - loss: 0.0228 - acc: 0.9938 - val_loss: 0.0293 - val_acc: 0.9912\n",
      "Epoch 18/700\n",
      " - 32s - loss: 0.0224 - acc: 0.9940 - val_loss: 0.0236 - val_acc: 0.9928\n",
      "Epoch 19/700\n",
      " - 32s - loss: 0.0220 - acc: 0.9941 - val_loss: 0.0284 - val_acc: 0.9916\n",
      "Epoch 20/700\n",
      " - 32s - loss: 0.0218 - acc: 0.9941 - val_loss: 0.0243 - val_acc: 0.9926\n",
      "Epoch 21/700\n",
      " - 32s - loss: 0.0213 - acc: 0.9944 - val_loss: 0.0239 - val_acc: 0.9932\n",
      "Epoch 22/700\n",
      " - 32s - loss: 0.0211 - acc: 0.9944 - val_loss: 0.0235 - val_acc: 0.9921\n",
      "Epoch 23/700\n",
      " - 32s - loss: 0.0208 - acc: 0.9945 - val_loss: 0.0287 - val_acc: 0.9916\n",
      "Epoch 24/700\n",
      " - 32s - loss: 0.0205 - acc: 0.9946 - val_loss: 0.0221 - val_acc: 0.9936\n",
      "Epoch 25/700\n",
      " - 32s - loss: 0.0203 - acc: 0.9947 - val_loss: 0.0287 - val_acc: 0.9912\n",
      "Epoch 26/700\n",
      " - 32s - loss: 0.0201 - acc: 0.9947 - val_loss: 0.0225 - val_acc: 0.9939\n",
      "Epoch 27/700\n",
      " - 32s - loss: 0.0199 - acc: 0.9948 - val_loss: 0.0256 - val_acc: 0.9917\n",
      "Epoch 28/700\n",
      " - 32s - loss: 0.0197 - acc: 0.9949 - val_loss: 0.0223 - val_acc: 0.9932\n",
      "Epoch 29/700\n",
      " - 32s - loss: 0.0195 - acc: 0.9949 - val_loss: 0.0255 - val_acc: 0.9930\n",
      "Epoch 30/700\n",
      " - 32s - loss: 0.0192 - acc: 0.9950 - val_loss: 0.0226 - val_acc: 0.9935\n",
      "Epoch 31/700\n",
      " - 32s - loss: 0.0190 - acc: 0.9951 - val_loss: 0.0255 - val_acc: 0.9929\n",
      "Epoch 32/700\n",
      " - 32s - loss: 0.0190 - acc: 0.9951 - val_loss: 0.0274 - val_acc: 0.9914\n",
      "Epoch 33/700\n",
      " - 32s - loss: 0.0187 - acc: 0.9952 - val_loss: 0.0218 - val_acc: 0.9939\n",
      "Epoch 34/700\n",
      " - 32s - loss: 0.0185 - acc: 0.9953 - val_loss: 0.0252 - val_acc: 0.9919\n",
      "Epoch 35/700\n",
      " - 32s - loss: 0.0184 - acc: 0.9953 - val_loss: 0.0212 - val_acc: 0.9942\n",
      "Epoch 36/700\n",
      " - 32s - loss: 0.0182 - acc: 0.9954 - val_loss: 0.0204 - val_acc: 0.9945\n",
      "Epoch 37/700\n",
      " - 33s - loss: 0.0181 - acc: 0.9954 - val_loss: 0.0258 - val_acc: 0.9921\n",
      "Epoch 38/700\n",
      " - 34s - loss: 0.0180 - acc: 0.9954 - val_loss: 0.0235 - val_acc: 0.9931\n",
      "Epoch 39/700\n",
      " - 33s - loss: 0.0178 - acc: 0.9955 - val_loss: 0.0209 - val_acc: 0.9936\n",
      "Epoch 40/700\n",
      " - 32s - loss: 0.0178 - acc: 0.9955 - val_loss: 0.0226 - val_acc: 0.9923\n",
      "Epoch 41/700\n",
      " - 32s - loss: 0.0176 - acc: 0.9955 - val_loss: 0.0227 - val_acc: 0.9930\n",
      "Epoch 42/700\n",
      " - 32s - loss: 0.0175 - acc: 0.9956 - val_loss: 0.0229 - val_acc: 0.9927\n",
      "Epoch 43/700\n",
      " - 32s - loss: 0.0175 - acc: 0.9956 - val_loss: 0.0243 - val_acc: 0.9924\n",
      "Epoch 44/700\n",
      " - 32s - loss: 0.0173 - acc: 0.9956 - val_loss: 0.0222 - val_acc: 0.9940\n",
      "Epoch 45/700\n",
      " - 32s - loss: 0.0173 - acc: 0.9957 - val_loss: 0.0219 - val_acc: 0.9935\n",
      "Epoch 46/700\n",
      " - 32s - loss: 0.0172 - acc: 0.9957 - val_loss: 0.0249 - val_acc: 0.9923\n",
      "Epoch 47/700\n",
      " - 32s - loss: 0.0171 - acc: 0.9957 - val_loss: 0.0226 - val_acc: 0.9938\n",
      "Epoch 48/700\n",
      " - 32s - loss: 0.0168 - acc: 0.9958 - val_loss: 0.0198 - val_acc: 0.9945\n",
      "Epoch 49/700\n",
      " - 32s - loss: 0.0168 - acc: 0.9958 - val_loss: 0.0230 - val_acc: 0.9926\n",
      "Epoch 50/700\n",
      " - 32s - loss: 0.0169 - acc: 0.9958 - val_loss: 0.0225 - val_acc: 0.9931\n",
      "Epoch 51/700\n",
      " - 32s - loss: 0.0166 - acc: 0.9959 - val_loss: 0.0209 - val_acc: 0.9937\n",
      "Epoch 52/700\n",
      " - 32s - loss: 0.0166 - acc: 0.9959 - val_loss: 0.0252 - val_acc: 0.9927\n",
      "Epoch 53/700\n",
      " - 32s - loss: 0.0164 - acc: 0.9959 - val_loss: 0.0207 - val_acc: 0.9940\n",
      "Epoch 54/700\n",
      " - 32s - loss: 0.0164 - acc: 0.9959 - val_loss: 0.0261 - val_acc: 0.9923\n",
      "Epoch 55/700\n",
      " - 32s - loss: 0.0164 - acc: 0.9959 - val_loss: 0.0196 - val_acc: 0.9946\n",
      "Epoch 56/700\n",
      " - 32s - loss: 0.0163 - acc: 0.9960 - val_loss: 0.0223 - val_acc: 0.9934\n",
      "Epoch 57/700\n",
      " - 32s - loss: 0.0163 - acc: 0.9960 - val_loss: 0.0229 - val_acc: 0.9941\n",
      "Epoch 58/700\n",
      " - 32s - loss: 0.0162 - acc: 0.9960 - val_loss: 0.0197 - val_acc: 0.9947\n",
      "Epoch 59/700\n",
      " - 32s - loss: 0.0161 - acc: 0.9960 - val_loss: 0.0199 - val_acc: 0.9947\n",
      "Epoch 60/700\n",
      " - 32s - loss: 0.0161 - acc: 0.9960 - val_loss: 0.0232 - val_acc: 0.9925\n",
      "Epoch 61/700\n",
      " - 32s - loss: 0.0160 - acc: 0.9961 - val_loss: 0.0233 - val_acc: 0.9929\n",
      "Epoch 62/700\n",
      " - 32s - loss: 0.0159 - acc: 0.9961 - val_loss: 0.0207 - val_acc: 0.9940\n",
      "Epoch 63/700\n",
      " - 32s - loss: 0.0158 - acc: 0.9961 - val_loss: 0.0199 - val_acc: 0.9945\n",
      "Epoch 64/700\n",
      " - 32s - loss: 0.0158 - acc: 0.9961 - val_loss: 0.0245 - val_acc: 0.9927\n",
      "Epoch 65/700\n",
      " - 32s - loss: 0.0157 - acc: 0.9962 - val_loss: 0.0210 - val_acc: 0.9946\n",
      "Epoch 66/700\n",
      " - 32s - loss: 0.0157 - acc: 0.9962 - val_loss: 0.0181 - val_acc: 0.9950\n",
      "Epoch 67/700\n",
      " - 32s - loss: 0.0156 - acc: 0.9962 - val_loss: 0.0197 - val_acc: 0.9946\n",
      "Epoch 68/700\n",
      " - 32s - loss: 0.0155 - acc: 0.9962 - val_loss: 0.0223 - val_acc: 0.9937\n",
      "Epoch 69/700\n",
      " - 32s - loss: 0.0154 - acc: 0.9962 - val_loss: 0.0218 - val_acc: 0.9926\n",
      "Epoch 70/700\n",
      " - 32s - loss: 0.0154 - acc: 0.9963 - val_loss: 0.0184 - val_acc: 0.9949\n",
      "Epoch 71/700\n",
      " - 32s - loss: 0.0153 - acc: 0.9963 - val_loss: 0.0197 - val_acc: 0.9949\n",
      "Epoch 72/700\n",
      " - 32s - loss: 0.0154 - acc: 0.9962 - val_loss: 0.0231 - val_acc: 0.9937\n",
      "Epoch 73/700\n",
      " - 32s - loss: 0.0153 - acc: 0.9963 - val_loss: 0.0190 - val_acc: 0.9950\n",
      "Epoch 74/700\n",
      " - 32s - loss: 0.0152 - acc: 0.9963 - val_loss: 0.0193 - val_acc: 0.9949\n",
      "Epoch 75/700\n",
      " - 32s - loss: 0.0151 - acc: 0.9963 - val_loss: 0.0211 - val_acc: 0.9945\n",
      "Epoch 76/700\n",
      " - 32s - loss: 0.0152 - acc: 0.9963 - val_loss: 0.0191 - val_acc: 0.9942\n",
      "Epoch 77/700\n",
      " - 32s - loss: 0.0151 - acc: 0.9963 - val_loss: 0.0193 - val_acc: 0.9948\n",
      "Epoch 78/700\n",
      " - 32s - loss: 0.0150 - acc: 0.9964 - val_loss: 0.0215 - val_acc: 0.9938\n",
      "Epoch 79/700\n",
      " - 32s - loss: 0.0151 - acc: 0.9963 - val_loss: 0.0186 - val_acc: 0.9949\n",
      "Epoch 80/700\n",
      " - 32s - loss: 0.0150 - acc: 0.9963 - val_loss: 0.0184 - val_acc: 0.9951\n",
      "Epoch 81/700\n",
      " - 32s - loss: 0.0148 - acc: 0.9964 - val_loss: 0.0194 - val_acc: 0.9944\n",
      "Epoch 82/700\n",
      " - 32s - loss: 0.0148 - acc: 0.9964 - val_loss: 0.0194 - val_acc: 0.9943\n",
      "Epoch 83/700\n",
      " - 32s - loss: 0.0149 - acc: 0.9964 - val_loss: 0.0181 - val_acc: 0.9955\n",
      "Epoch 84/700\n",
      " - 32s - loss: 0.0147 - acc: 0.9964 - val_loss: 0.0185 - val_acc: 0.9951\n",
      "Epoch 85/700\n",
      " - 32s - loss: 0.0147 - acc: 0.9964 - val_loss: 0.0188 - val_acc: 0.9954\n",
      "Epoch 86/700\n",
      " - 32s - loss: 0.0147 - acc: 0.9964 - val_loss: 0.0190 - val_acc: 0.9949\n",
      "Epoch 87/700\n",
      " - 32s - loss: 0.0147 - acc: 0.9965 - val_loss: 0.0176 - val_acc: 0.9952\n",
      "Epoch 88/700\n",
      " - 32s - loss: 0.0146 - acc: 0.9965 - val_loss: 0.0184 - val_acc: 0.9951\n",
      "Epoch 89/700\n",
      " - 32s - loss: 0.0145 - acc: 0.9965 - val_loss: 0.0189 - val_acc: 0.9952\n",
      "Epoch 90/700\n",
      " - 32s - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0180 - val_acc: 0.9955\n",
      "Epoch 91/700\n",
      " - 32s - loss: 0.0146 - acc: 0.9964 - val_loss: 0.0179 - val_acc: 0.9957\n",
      "Epoch 92/700\n",
      " - 32s - loss: 0.0145 - acc: 0.9965 - val_loss: 0.0177 - val_acc: 0.9952\n",
      "Epoch 93/700\n",
      " - 32s - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0176 - val_acc: 0.9953\n",
      "Epoch 94/700\n",
      " - 32s - loss: 0.0144 - acc: 0.9965 - val_loss: 0.0176 - val_acc: 0.9952\n",
      "Epoch 95/700\n",
      " - 32s - loss: 0.0143 - acc: 0.9965 - val_loss: 0.0181 - val_acc: 0.9951\n",
      "Epoch 96/700\n",
      " - 32s - loss: 0.0143 - acc: 0.9965 - val_loss: 0.0178 - val_acc: 0.9953\n",
      "Epoch 97/700\n",
      " - 32s - loss: 0.0143 - acc: 0.9966 - val_loss: 0.0180 - val_acc: 0.9956\n",
      "Epoch 98/700\n",
      " - 32s - loss: 0.0143 - acc: 0.9966 - val_loss: 0.0163 - val_acc: 0.9955\n",
      "Epoch 99/700\n",
      " - 32s - loss: 0.0143 - acc: 0.9966 - val_loss: 0.0200 - val_acc: 0.9948\n",
      "Epoch 100/700\n",
      " - 32s - loss: 0.0142 - acc: 0.9966 - val_loss: 0.0192 - val_acc: 0.9947\n",
      "Epoch 101/700\n",
      " - 32s - loss: 0.0141 - acc: 0.9966 - val_loss: 0.0171 - val_acc: 0.9954\n",
      "Epoch 102/700\n",
      " - 32s - loss: 0.0141 - acc: 0.9966 - val_loss: 0.0170 - val_acc: 0.9958\n",
      "Epoch 103/700\n",
      " - 32s - loss: 0.0141 - acc: 0.9966 - val_loss: 0.0183 - val_acc: 0.9958\n",
      "Epoch 104/700\n",
      " - 32s - loss: 0.0140 - acc: 0.9966 - val_loss: 0.0181 - val_acc: 0.9957\n",
      "Epoch 105/700\n",
      " - 32s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0188 - val_acc: 0.9956\n",
      "Epoch 106/700\n",
      " - 32s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0181 - val_acc: 0.9958\n",
      "Epoch 107/700\n",
      " - 32s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0175 - val_acc: 0.9957\n",
      "Epoch 108/700\n",
      " - 32s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0170 - val_acc: 0.9952\n",
      "Epoch 109/700\n",
      " - 32s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0168 - val_acc: 0.9953\n",
      "Epoch 110/700\n",
      " - 32s - loss: 0.0139 - acc: 0.9967 - val_loss: 0.0186 - val_acc: 0.9953\n",
      "Epoch 111/700\n",
      " - 32s - loss: 0.0138 - acc: 0.9967 - val_loss: 0.0166 - val_acc: 0.9959\n",
      "Epoch 112/700\n",
      " - 32s - loss: 0.0138 - acc: 0.9967 - val_loss: 0.0166 - val_acc: 0.9956\n",
      "Epoch 113/700\n",
      " - 32s - loss: 0.0137 - acc: 0.9967 - val_loss: 0.0166 - val_acc: 0.9960\n",
      "Epoch 114/700\n",
      " - 32s - loss: 0.0137 - acc: 0.9967 - val_loss: 0.0162 - val_acc: 0.9961\n",
      "Epoch 115/700\n",
      " - 32s - loss: 0.0138 - acc: 0.9967 - val_loss: 0.0162 - val_acc: 0.9960\n",
      "Epoch 116/700\n",
      " - 32s - loss: 0.0138 - acc: 0.9967 - val_loss: 0.0162 - val_acc: 0.9955\n",
      "Epoch 117/700\n",
      " - 32s - loss: 0.0136 - acc: 0.9968 - val_loss: 0.0154 - val_acc: 0.9959\n",
      "Epoch 118/700\n",
      " - 32s - loss: 0.0136 - acc: 0.9968 - val_loss: 0.0171 - val_acc: 0.9956\n",
      "Epoch 119/700\n",
      " - 32s - loss: 0.0136 - acc: 0.9968 - val_loss: 0.0184 - val_acc: 0.9952\n",
      "Epoch 120/700\n",
      " - 32s - loss: 0.0136 - acc: 0.9968 - val_loss: 0.0166 - val_acc: 0.9958\n",
      "Epoch 121/700\n",
      " - 32s - loss: 0.0136 - acc: 0.9967 - val_loss: 0.0162 - val_acc: 0.9957\n",
      "Epoch 122/700\n",
      " - 32s - loss: 0.0135 - acc: 0.9968 - val_loss: 0.0166 - val_acc: 0.9957\n",
      "Epoch 123/700\n",
      " - 32s - loss: 0.0137 - acc: 0.9967 - val_loss: 0.0179 - val_acc: 0.9952\n",
      "Epoch 124/700\n",
      " - 32s - loss: 0.0135 - acc: 0.9968 - val_loss: 0.0169 - val_acc: 0.9960\n",
      "Epoch 125/700\n",
      " - 32s - loss: 0.0134 - acc: 0.9968 - val_loss: 0.0159 - val_acc: 0.9955\n",
      "Epoch 126/700\n",
      " - 32s - loss: 0.0135 - acc: 0.9968 - val_loss: 0.0156 - val_acc: 0.9964\n",
      "Epoch 127/700\n",
      " - 32s - loss: 0.0134 - acc: 0.9968 - val_loss: 0.0166 - val_acc: 0.9962\n",
      "Epoch 128/700\n",
      " - 32s - loss: 0.0133 - acc: 0.9969 - val_loss: 0.0171 - val_acc: 0.9954\n",
      "Epoch 129/700\n",
      " - 32s - loss: 0.0133 - acc: 0.9968 - val_loss: 0.0166 - val_acc: 0.9961\n",
      "Epoch 130/700\n",
      " - 32s - loss: 0.0134 - acc: 0.9968 - val_loss: 0.0164 - val_acc: 0.9962\n",
      "Epoch 131/700\n",
      " - 32s - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0159 - val_acc: 0.9960\n",
      "Epoch 132/700\n",
      " - 32s - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0175 - val_acc: 0.9953\n",
      "Epoch 133/700\n",
      " - 32s - loss: 0.0133 - acc: 0.9968 - val_loss: 0.0186 - val_acc: 0.9952\n",
      "Epoch 134/700\n",
      " - 32s - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0168 - val_acc: 0.9960\n",
      "Epoch 135/700\n",
      " - 32s - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0174 - val_acc: 0.9959\n",
      "Epoch 136/700\n",
      " - 32s - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0173 - val_acc: 0.9954\n",
      "Epoch 137/700\n",
      " - 32s - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0164 - val_acc: 0.9954\n",
      "Epoch 138/700\n",
      " - 32s - loss: 0.0131 - acc: 0.9969 - val_loss: 0.0166 - val_acc: 0.9957\n",
      "Epoch 139/700\n",
      " - 32s - loss: 0.0131 - acc: 0.9969 - val_loss: 0.0143 - val_acc: 0.9963\n",
      "Epoch 140/700\n",
      " - 32s - loss: 0.0131 - acc: 0.9969 - val_loss: 0.0148 - val_acc: 0.9960\n",
      "Epoch 141/700\n",
      " - 32s - loss: 0.0130 - acc: 0.9969 - val_loss: 0.0159 - val_acc: 0.9963\n",
      "Epoch 142/700\n",
      " - 32s - loss: 0.0130 - acc: 0.9970 - val_loss: 0.0171 - val_acc: 0.9956\n",
      "Epoch 143/700\n",
      " - 32s - loss: 0.0129 - acc: 0.9969 - val_loss: 0.0150 - val_acc: 0.9962\n",
      "Epoch 144/700\n",
      " - 32s - loss: 0.0132 - acc: 0.9968 - val_loss: 0.0179 - val_acc: 0.9958\n",
      "Epoch 145/700\n",
      " - 32s - loss: 0.0129 - acc: 0.9970 - val_loss: 0.0146 - val_acc: 0.9961\n",
      "Epoch 146/700\n",
      " - 32s - loss: 0.0129 - acc: 0.9970 - val_loss: 0.0149 - val_acc: 0.9961\n",
      "Epoch 147/700\n",
      " - 32s - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0166 - val_acc: 0.9964\n",
      "Epoch 148/700\n",
      " - 32s - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0151 - val_acc: 0.9961\n",
      "Epoch 149/700\n",
      " - 32s - loss: 0.0129 - acc: 0.9970 - val_loss: 0.0158 - val_acc: 0.9957\n",
      "Epoch 150/700\n",
      " - 32s - loss: 0.0129 - acc: 0.9969 - val_loss: 0.0176 - val_acc: 0.9955\n",
      "Epoch 151/700\n",
      " - 32s - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0161 - val_acc: 0.9961\n",
      "Epoch 152/700\n",
      " - 32s - loss: 0.0129 - acc: 0.9969 - val_loss: 0.0161 - val_acc: 0.9956\n",
      "Epoch 153/700\n",
      " - 32s - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0157 - val_acc: 0.9962\n",
      "Epoch 154/700\n",
      " - 32s - loss: 0.0127 - acc: 0.9970 - val_loss: 0.0153 - val_acc: 0.9961\n",
      "Epoch 155/700\n",
      " - 32s - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0164 - val_acc: 0.9964\n",
      "Epoch 156/700\n",
      " - 32s - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0168 - val_acc: 0.9961\n",
      "Epoch 157/700\n",
      " - 32s - loss: 0.0127 - acc: 0.9970 - val_loss: 0.0155 - val_acc: 0.9963\n",
      "Epoch 158/700\n",
      " - 32s - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0161 - val_acc: 0.9960\n",
      "Epoch 159/700\n",
      " - 32s - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0169 - val_acc: 0.9961\n",
      "Epoch 160/700\n",
      " - 32s - loss: 0.0127 - acc: 0.9970 - val_loss: 0.0154 - val_acc: 0.9961\n",
      "Epoch 161/700\n",
      " - 32s - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0152 - val_acc: 0.9962\n",
      "Epoch 162/700\n",
      " - 32s - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0172 - val_acc: 0.9958\n",
      "Epoch 163/700\n",
      " - 32s - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0157 - val_acc: 0.9962\n",
      "Epoch 164/700\n",
      " - 32s - loss: 0.0125 - acc: 0.9971 - val_loss: 0.0151 - val_acc: 0.9961\n",
      "Epoch 165/700\n",
      " - 32s - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0156 - val_acc: 0.9961\n",
      "Epoch 166/700\n",
      " - 32s - loss: 0.0126 - acc: 0.9970 - val_loss: 0.0158 - val_acc: 0.9962\n",
      "Epoch 167/700\n",
      " - 32s - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0157 - val_acc: 0.9963\n",
      "Epoch 168/700\n",
      " - 32s - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0165 - val_acc: 0.9962\n",
      "Epoch 169/700\n",
      " - 32s - loss: 0.0125 - acc: 0.9971 - val_loss: 0.0156 - val_acc: 0.9966\n",
      "Epoch 170/700\n",
      " - 32s - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0163 - val_acc: 0.9961\n",
      "Epoch 171/700\n",
      " - 32s - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0168 - val_acc: 0.9957\n",
      "Epoch 172/700\n",
      " - 32s - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0162 - val_acc: 0.9963\n",
      "Epoch 173/700\n",
      " - 32s - loss: 0.0123 - acc: 0.9971 - val_loss: 0.0181 - val_acc: 0.9954\n",
      "Epoch 174/700\n",
      " - 32s - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0160 - val_acc: 0.9959\n",
      "Epoch 175/700\n",
      " - 32s - loss: 0.0124 - acc: 0.9971 - val_loss: 0.0155 - val_acc: 0.9962\n",
      "Epoch 176/700\n",
      " - 32s - loss: 0.0123 - acc: 0.9971 - val_loss: 0.0165 - val_acc: 0.9964\n",
      "Epoch 177/700\n",
      " - 32s - loss: 0.0123 - acc: 0.9971 - val_loss: 0.0169 - val_acc: 0.9963\n",
      "Epoch 178/700\n",
      " - 32s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0165 - val_acc: 0.9963\n",
      "Epoch 179/700\n",
      " - 32s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0171 - val_acc: 0.9958\n",
      "Epoch 180/700\n",
      " - 32s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0152 - val_acc: 0.9962\n",
      "Epoch 181/700\n",
      " - 32s - loss: 0.0124 - acc: 0.9970 - val_loss: 0.0152 - val_acc: 0.9957\n",
      "Epoch 182/700\n",
      " - 32s - loss: 0.0127 - acc: 0.9969 - val_loss: 0.0172 - val_acc: 0.9956\n",
      "Epoch 183/700\n",
      " - 32s - loss: 0.0126 - acc: 0.9969 - val_loss: 0.0172 - val_acc: 0.9957\n",
      "Epoch 184/700\n",
      " - 32s - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0171 - val_acc: 0.9957\n",
      "Epoch 185/700\n",
      " - 32s - loss: 0.0125 - acc: 0.9970 - val_loss: 0.0178 - val_acc: 0.9956\n",
      "Epoch 186/700\n",
      " - 32s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0160 - val_acc: 0.9960\n",
      "Epoch 187/700\n",
      " - 32s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0202 - val_acc: 0.9948\n",
      "Epoch 188/700\n",
      " - 32s - loss: 0.0121 - acc: 0.9971 - val_loss: 0.0158 - val_acc: 0.9962\n",
      "Epoch 189/700\n",
      " - 32s - loss: 0.0121 - acc: 0.9972 - val_loss: 0.0157 - val_acc: 0.9965\n",
      "Epoch 190/700\n",
      " - 32s - loss: 0.0121 - acc: 0.9972 - val_loss: 0.0167 - val_acc: 0.9962\n",
      "Epoch 191/700\n",
      " - 32s - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0164 - val_acc: 0.9965\n",
      "Epoch 192/700\n",
      " - 32s - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0168 - val_acc: 0.9964\n",
      "Epoch 193/700\n",
      " - 32s - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0157 - val_acc: 0.9964\n",
      "Epoch 194/700\n",
      " - 32s - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0147 - val_acc: 0.9963\n",
      "Epoch 195/700\n",
      " - 32s - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0160 - val_acc: 0.9963\n",
      "Epoch 196/700\n",
      " - 32s - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0170 - val_acc: 0.9964\n",
      "Epoch 197/700\n",
      " - 32s - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0173 - val_acc: 0.9963\n",
      "Epoch 198/700\n",
      " - 32s - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0181 - val_acc: 0.9955\n",
      "Epoch 199/700\n",
      " - 32s - loss: 0.0119 - acc: 0.9972 - val_loss: 0.0157 - val_acc: 0.9961\n",
      "Epoch 200/700\n",
      " - 32s - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0165 - val_acc: 0.9964\n",
      "Epoch 201/700\n",
      " - 32s - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0162 - val_acc: 0.9963\n",
      "Epoch 202/700\n",
      " - 32s - loss: 0.0120 - acc: 0.9971 - val_loss: 0.0150 - val_acc: 0.9965\n",
      "Epoch 203/700\n",
      " - 32s - loss: 0.0121 - acc: 0.9971 - val_loss: 0.0171 - val_acc: 0.9958\n",
      "Epoch 204/700\n",
      " - 32s - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0150 - val_acc: 0.9964\n",
      "Epoch 205/700\n",
      " - 32s - loss: 0.0117 - acc: 0.9973 - val_loss: 0.0172 - val_acc: 0.9965\n",
      "Epoch 206/700\n",
      " - 32s - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0165 - val_acc: 0.9963\n",
      "Epoch 207/700\n",
      " - 32s - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0153 - val_acc: 0.9964\n",
      "Epoch 208/700\n",
      " - 32s - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0152 - val_acc: 0.9965\n",
      "Epoch 209/700\n",
      " - 32s - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0151 - val_acc: 0.9964\n",
      "Epoch 210/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0163 - val_acc: 0.9964\n",
      "Epoch 211/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0177 - val_acc: 0.9957\n",
      "Epoch 212/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0158 - val_acc: 0.9965\n",
      "Epoch 213/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0163 - val_acc: 0.9964\n",
      "Epoch 214/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0156 - val_acc: 0.9965\n",
      "Epoch 215/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0159 - val_acc: 0.9962\n",
      "Epoch 216/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0159 - val_acc: 0.9964\n",
      "Epoch 217/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9973 - val_loss: 0.0163 - val_acc: 0.9965\n",
      "Epoch 218/700\n",
      " - 32s - loss: 0.0116 - acc: 0.9972 - val_loss: 0.0162 - val_acc: 0.9965\n",
      "Epoch 219/700\n",
      " - 32s - loss: 0.0118 - acc: 0.9972 - val_loss: 0.0171 - val_acc: 0.9955\n",
      "Epoch 220/700\n",
      " - 32s - loss: 0.0115 - acc: 0.9973 - val_loss: 0.0143 - val_acc: 0.9964\n",
      "Epoch 221/700\n",
      " - 32s - loss: 0.0115 - acc: 0.9973 - val_loss: 0.0157 - val_acc: 0.9966\n",
      "Epoch 222/700\n",
      " - 32s - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0172 - val_acc: 0.9956\n",
      "Epoch 223/700\n",
      " - 32s - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0136 - val_acc: 0.9965\n",
      "Epoch 224/700\n",
      " - 32s - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0150 - val_acc: 0.9964\n",
      "Epoch 225/700\n",
      " - 32s - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0196 - val_acc: 0.9949\n",
      "Epoch 226/700\n",
      " - 32s - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0160 - val_acc: 0.9966\n",
      "Epoch 227/700\n",
      " - 32s - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0162 - val_acc: 0.9963\n",
      "Epoch 228/700\n",
      " - 32s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0162 - val_acc: 0.9965\n",
      "Epoch 229/700\n",
      " - 32s - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0126 - val_acc: 0.9967\n",
      "Epoch 230/700\n",
      " - 32s - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0162 - val_acc: 0.9963\n",
      "Epoch 231/700\n",
      " - 32s - loss: 0.0113 - acc: 0.9973 - val_loss: 0.0165 - val_acc: 0.9964\n",
      "Epoch 232/700\n",
      " - 32s - loss: 0.0112 - acc: 0.9973 - val_loss: 0.0151 - val_acc: 0.9966\n",
      "Epoch 233/700\n",
      " - 32s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0151 - val_acc: 0.9965\n",
      "Epoch 234/700\n",
      " - 32s - loss: 0.0114 - acc: 0.9973 - val_loss: 0.0178 - val_acc: 0.9954\n",
      "Epoch 235/700\n",
      " - 32s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0161 - val_acc: 0.9964\n",
      "Epoch 236/700\n",
      " - 32s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0162 - val_acc: 0.9966\n",
      "Epoch 237/700\n",
      " - 32s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0178 - val_acc: 0.9958\n",
      "Epoch 238/700\n",
      " - 32s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0176 - val_acc: 0.9959\n",
      "Epoch 239/700\n",
      " - 32s - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0162 - val_acc: 0.9964\n",
      "Epoch 240/700\n",
      " - 32s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0160 - val_acc: 0.9966\n",
      "Epoch 241/700\n",
      " - 32s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0162 - val_acc: 0.9962\n",
      "Epoch 242/700\n",
      " - 32s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0161 - val_acc: 0.9965\n",
      "Epoch 243/700\n",
      " - 32s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0161 - val_acc: 0.9964\n",
      "Epoch 244/700\n",
      " - 32s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0167 - val_acc: 0.9964\n",
      "Epoch 245/700\n",
      " - 32s - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0139 - val_acc: 0.9964\n",
      "Epoch 246/700\n",
      " - 32s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0128 - val_acc: 0.9968\n",
      "Epoch 247/700\n",
      " - 32s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0152 - val_acc: 0.9965\n",
      "Epoch 248/700\n",
      " - 32s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0160 - val_acc: 0.9964\n",
      "Epoch 249/700\n",
      " - 32s - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0151 - val_acc: 0.9965\n",
      "Epoch 250/700\n",
      " - 32s - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0166 - val_acc: 0.9964\n",
      "Epoch 251/700\n",
      " - 32s - loss: 0.0109 - acc: 0.9975 - val_loss: 0.0163 - val_acc: 0.9961\n",
      "Epoch 252/700\n",
      " - 32s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0161 - val_acc: 0.9965\n",
      "Epoch 253/700\n",
      " - 32s - loss: 0.0107 - acc: 0.9975 - val_loss: 0.0154 - val_acc: 0.9966\n",
      "Epoch 254/700\n",
      " - 32s - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0162 - val_acc: 0.9957\n",
      "Epoch 255/700\n",
      " - 32s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0163 - val_acc: 0.9959\n",
      "Epoch 256/700\n",
      " - 32s - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0149 - val_acc: 0.9958\n",
      "Epoch 257/700\n",
      " - 32s - loss: 0.0109 - acc: 0.9974 - val_loss: 0.0162 - val_acc: 0.9959\n",
      "Epoch 258/700\n",
      " - 32s - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0163 - val_acc: 0.9963\n",
      "Epoch 259/700\n",
      " - 32s - loss: 0.0107 - acc: 0.9975 - val_loss: 0.0139 - val_acc: 0.9965\n",
      "Epoch 260/700\n",
      " - 32s - loss: 0.0106 - acc: 0.9975 - val_loss: 0.0154 - val_acc: 0.9963\n",
      "Epoch 261/700\n",
      " - 32s - loss: 0.0106 - acc: 0.9975 - val_loss: 0.0138 - val_acc: 0.9966\n",
      "Epoch 262/700\n",
      " - 32s - loss: 0.0106 - acc: 0.9975 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "Epoch 263/700\n",
      " - 32s - loss: 0.0107 - acc: 0.9975 - val_loss: 0.0165 - val_acc: 0.9965\n",
      "Epoch 264/700\n",
      " - 32s - loss: 0.0106 - acc: 0.9976 - val_loss: 0.0189 - val_acc: 0.9957\n",
      "Epoch 265/700\n",
      " - 32s - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0179 - val_acc: 0.9957\n",
      "Epoch 266/700\n",
      " - 32s - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0127 - val_acc: 0.9969\n",
      "Epoch 267/700\n",
      " - 32s - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0182 - val_acc: 0.9960\n",
      "Epoch 268/700\n",
      " - 32s - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0150 - val_acc: 0.9966\n",
      "Epoch 269/700\n",
      " - 32s - loss: 0.0105 - acc: 0.9976 - val_loss: 0.0241 - val_acc: 0.9939\n",
      "Epoch 270/700\n",
      " - 32s - loss: 0.0104 - acc: 0.9976 - val_loss: 0.0140 - val_acc: 0.9966\n",
      "Epoch 271/700\n",
      " - 32s - loss: 0.0104 - acc: 0.9976 - val_loss: 0.0137 - val_acc: 0.9965\n",
      "Epoch 272/700\n",
      " - 32s - loss: 0.0104 - acc: 0.9976 - val_loss: 0.0159 - val_acc: 0.9966\n",
      "Epoch 273/700\n",
      " - 32s - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0159 - val_acc: 0.9966\n",
      "Epoch 274/700\n",
      " - 32s - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0157 - val_acc: 0.9966\n",
      "Epoch 275/700\n",
      " - 32s - loss: 0.0103 - acc: 0.9977 - val_loss: 0.0139 - val_acc: 0.9966\n",
      "Epoch 276/700\n",
      " - 32s - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0152 - val_acc: 0.9966\n",
      "Epoch 277/700\n",
      " - 32s - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0158 - val_acc: 0.9966\n",
      "Epoch 278/700\n",
      " - 32s - loss: 0.0107 - acc: 0.9974 - val_loss: 0.0131 - val_acc: 0.9967\n",
      "Epoch 279/700\n",
      " - 32s - loss: 0.0102 - acc: 0.9977 - val_loss: 0.0159 - val_acc: 0.9966\n",
      "Epoch 280/700\n",
      " - 32s - loss: 0.0102 - acc: 0.9976 - val_loss: 0.0168 - val_acc: 0.9965\n",
      "Epoch 281/700\n",
      " - 32s - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0158 - val_acc: 0.9965\n",
      "Epoch 282/700\n",
      " - 32s - loss: 0.0102 - acc: 0.9977 - val_loss: 0.0163 - val_acc: 0.9966\n",
      "Epoch 283/700\n",
      " - 32s - loss: 0.0102 - acc: 0.9977 - val_loss: 0.0144 - val_acc: 0.9964\n",
      "Epoch 284/700\n",
      " - 32s - loss: 0.0102 - acc: 0.9977 - val_loss: 0.0155 - val_acc: 0.9967\n",
      "Epoch 285/700\n",
      " - 32s - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0161 - val_acc: 0.9965\n",
      "Epoch 286/700\n",
      " - 32s - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0160 - val_acc: 0.9966\n",
      "Epoch 287/700\n",
      " - 32s - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0158 - val_acc: 0.9967\n",
      "Epoch 288/700\n",
      " - 32s - loss: 0.0102 - acc: 0.9977 - val_loss: 0.0157 - val_acc: 0.9967\n",
      "Epoch 289/700\n",
      " - 32s - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0159 - val_acc: 0.9965\n",
      "Epoch 290/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0155 - val_acc: 0.9968\n",
      "Epoch 291/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0122 - val_acc: 0.9970\n",
      "Epoch 292/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0154 - val_acc: 0.9968\n",
      "Epoch 293/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0171 - val_acc: 0.9954\n",
      "Epoch 294/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0162 - val_acc: 0.9965\n",
      "Epoch 295/700\n",
      " - 32s - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0151 - val_acc: 0.9964\n",
      "Epoch 296/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0154 - val_acc: 0.9966\n",
      "Epoch 297/700\n",
      " - 32s - loss: 0.0101 - acc: 0.9977 - val_loss: 0.0162 - val_acc: 0.9965\n",
      "Epoch 298/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0163 - val_acc: 0.9967\n",
      "Epoch 299/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0157 - val_acc: 0.9966\n",
      "Epoch 300/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0150 - val_acc: 0.9966\n",
      "Epoch 301/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9978 - val_loss: 0.0183 - val_acc: 0.9955\n",
      "Epoch 302/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0115 - val_acc: 0.9970\n",
      "Epoch 303/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0155 - val_acc: 0.9962\n",
      "Epoch 304/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0155 - val_acc: 0.9967\n",
      "Epoch 305/700\n",
      " - 32s - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0137 - val_acc: 0.9964\n",
      "Epoch 306/700\n",
      " - 32s - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0776 - val_acc: 0.9843\n",
      "Epoch 307/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0128 - val_acc: 0.9965\n",
      "Epoch 308/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0124 - val_acc: 0.9968\n",
      "Epoch 309/700\n",
      " - 32s - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0157 - val_acc: 0.9967\n",
      "Epoch 310/700\n",
      " - 32s - loss: 0.0099 - acc: 0.9977 - val_loss: 0.0148 - val_acc: 0.9966\n",
      "Epoch 311/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "Epoch 312/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0138 - val_acc: 0.9967\n",
      "Epoch 313/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0133 - val_acc: 0.9967\n",
      "Epoch 314/700\n",
      " - 32s - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0163 - val_acc: 0.9967\n",
      "Epoch 315/700\n",
      " - 32s - loss: 0.0098 - acc: 0.9978 - val_loss: 0.0153 - val_acc: 0.9961\n",
      "Epoch 316/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0158 - val_acc: 0.9966\n",
      "Epoch 317/700\n",
      " - 32s - loss: 0.0100 - acc: 0.9977 - val_loss: 0.0162 - val_acc: 0.9965\n",
      "Epoch 318/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0150 - val_acc: 0.9967\n",
      "Epoch 319/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0142 - val_acc: 0.9967\n",
      "Epoch 320/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0159 - val_acc: 0.9967\n",
      "Epoch 321/700\n",
      " - 32s - loss: 0.0096 - acc: 0.9979 - val_loss: 0.0153 - val_acc: 0.9967\n",
      "Epoch 322/700\n",
      " - 32s - loss: 0.0097 - acc: 0.9978 - val_loss: 0.0112 - val_acc: 0.9975\n",
      "Epoch 323/700\n",
      " - 32s - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0153 - val_acc: 0.9966\n",
      "Epoch 324/700\n",
      " - 32s - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0147 - val_acc: 0.9968\n",
      "Epoch 325/700\n",
      " - 32s - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0170 - val_acc: 0.9966\n",
      "Epoch 326/700\n",
      " - 32s - loss: 0.0096 - acc: 0.9979 - val_loss: 0.0141 - val_acc: 0.9966\n",
      "Epoch 327/700\n",
      " - 32s - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0164 - val_acc: 0.9966\n",
      "Epoch 328/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 329/700\n",
      " - 32s - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0121 - val_acc: 0.9970\n",
      "Epoch 330/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0156 - val_acc: 0.9967\n",
      "Epoch 331/700\n",
      " - 32s - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Epoch 332/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0144 - val_acc: 0.9968\n",
      "Epoch 333/700\n",
      " - 32s - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0148 - val_acc: 0.9968\n",
      "Epoch 334/700\n",
      " - 32s - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "Epoch 335/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0167 - val_acc: 0.9966\n",
      "Epoch 336/700\n",
      " - 32s - loss: 0.0095 - acc: 0.9979 - val_loss: 0.0125 - val_acc: 0.9969\n",
      "Epoch 337/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0147 - val_acc: 0.9967\n",
      "Epoch 338/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0139 - val_acc: 0.9968\n",
      "Epoch 339/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0152 - val_acc: 0.9968\n",
      "Epoch 340/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0149 - val_acc: 0.9967\n",
      "Epoch 341/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0153 - val_acc: 0.9967\n",
      "Epoch 342/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0159 - val_acc: 0.9967\n",
      "Epoch 343/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0122 - val_acc: 0.9970\n",
      "Epoch 344/700\n",
      " - 32s - loss: 0.0095 - acc: 0.9978 - val_loss: 0.0157 - val_acc: 0.9966\n",
      "Epoch 345/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9980 - val_loss: 0.0151 - val_acc: 0.9967\n",
      "Epoch 346/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0123 - val_acc: 0.9969\n",
      "Epoch 347/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0121 - val_acc: 0.9969\n",
      "Epoch 348/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0131 - val_acc: 0.9970\n",
      "Epoch 349/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0148 - val_acc: 0.9962\n",
      "Epoch 350/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0149 - val_acc: 0.9967\n",
      "Epoch 351/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0110 - val_acc: 0.9976\n",
      "Epoch 352/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0165 - val_acc: 0.9964\n",
      "Epoch 353/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0146 - val_acc: 0.9961\n",
      "Epoch 354/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0150 - val_acc: 0.9968\n",
      "Epoch 355/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0124 - val_acc: 0.9968\n",
      "Epoch 356/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0108 - val_acc: 0.9976\n",
      "Epoch 357/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0146 - val_acc: 0.9968\n",
      "Epoch 358/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0124 - val_acc: 0.9970\n",
      "Epoch 359/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0131 - val_acc: 0.9970\n",
      "Epoch 360/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0153 - val_acc: 0.9968\n",
      "Epoch 361/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0156 - val_acc: 0.9967\n",
      "Epoch 362/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0151 - val_acc: 0.9967\n",
      "Epoch 363/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0149 - val_acc: 0.9968\n",
      "Epoch 364/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0154 - val_acc: 0.9967\n",
      "Epoch 365/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0139 - val_acc: 0.9968\n",
      "Epoch 366/700\n",
      " - 32s - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0153 - val_acc: 0.9968\n",
      "Epoch 367/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0149 - val_acc: 0.9968\n",
      "Epoch 368/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0159 - val_acc: 0.9967\n",
      "Epoch 369/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0138 - val_acc: 0.9967\n",
      "Epoch 370/700\n",
      " - 32s - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0119 - val_acc: 0.9970\n",
      "Epoch 371/700\n",
      " - 32s - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0152 - val_acc: 0.9968\n",
      "Epoch 372/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0122 - val_acc: 0.9970\n",
      "Epoch 373/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0154 - val_acc: 0.9968\n",
      "Epoch 374/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0144 - val_acc: 0.9968\n",
      "Epoch 375/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0149 - val_acc: 0.9968\n",
      "Epoch 376/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0158 - val_acc: 0.9966\n",
      "Epoch 377/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0152 - val_acc: 0.9962\n",
      "Epoch 378/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0142 - val_acc: 0.9968\n",
      "Epoch 379/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0160 - val_acc: 0.9967\n",
      "Epoch 380/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0139 - val_acc: 0.9965\n",
      "Epoch 381/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9979 - val_loss: 0.0148 - val_acc: 0.9966\n",
      "Epoch 382/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0157 - val_acc: 0.9966\n",
      "Epoch 383/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0122 - val_acc: 0.9971\n",
      "Epoch 384/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0158 - val_acc: 0.9968\n",
      "Epoch 385/700\n",
      " - 32s - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 386/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0113 - val_acc: 0.9976\n",
      "Epoch 387/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0170 - val_acc: 0.9962\n",
      "Epoch 388/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0152 - val_acc: 0.9967\n",
      "Epoch 389/700\n",
      " - 32s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.0150 - val_acc: 0.9966\n",
      "Epoch 390/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0115 - val_acc: 0.9972\n",
      "Epoch 391/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0153 - val_acc: 0.9968\n",
      "Epoch 392/700\n",
      " - 32s - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0114 - val_acc: 0.9974\n",
      "Epoch 393/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0159 - val_acc: 0.9966\n",
      "Epoch 394/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Epoch 395/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0154 - val_acc: 0.9967\n",
      "Epoch 396/700\n",
      " - 32s - loss: 0.0090 - acc: 0.9980 - val_loss: 0.0146 - val_acc: 0.9962\n",
      "Epoch 397/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0152 - val_acc: 0.9968\n",
      "Epoch 398/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0149 - val_acc: 0.9968\n",
      "Epoch 399/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0153 - val_acc: 0.9968\n",
      "Epoch 400/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0120 - val_acc: 0.9968\n",
      "Epoch 401/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0135 - val_acc: 0.9971\n",
      "Epoch 402/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0156 - val_acc: 0.9968\n",
      "Epoch 403/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0152 - val_acc: 0.9967\n",
      "Epoch 404/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0156 - val_acc: 0.9967\n",
      "Epoch 405/700\n",
      " - 32s - loss: 0.0091 - acc: 0.9980 - val_loss: 0.0173 - val_acc: 0.9960\n",
      "Epoch 406/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 407/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0148 - val_acc: 0.9968\n",
      "Epoch 408/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0142 - val_acc: 0.9969\n",
      "Epoch 409/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0149 - val_acc: 0.9968\n",
      "Epoch 410/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0150 - val_acc: 0.9968\n",
      "Epoch 411/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 412/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9981 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 413/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0110 - val_acc: 0.9976\n",
      "Epoch 414/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9981 - val_loss: 0.0154 - val_acc: 0.9969\n",
      "Epoch 415/700\n",
      " - 32s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.0125 - val_acc: 0.9970\n",
      "Epoch 416/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0154 - val_acc: 0.9968\n",
      "Epoch 417/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9981 - val_loss: 0.0117 - val_acc: 0.9971\n",
      "Epoch 418/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Epoch 419/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0161 - val_acc: 0.9968\n",
      "Epoch 420/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0105 - val_acc: 0.9977\n",
      "Epoch 421/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0131 - val_acc: 0.9952\n",
      "Epoch 422/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 423/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9981 - val_loss: 0.0108 - val_acc: 0.9976\n",
      "Epoch 424/700\n",
      " - 32s - loss: 0.0088 - acc: 0.9980 - val_loss: 0.0171 - val_acc: 0.9965\n",
      "Epoch 425/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0158 - val_acc: 0.9967\n",
      "Epoch 426/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0134 - val_acc: 0.9970\n",
      "Epoch 427/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0156 - val_acc: 0.9968\n",
      "Epoch 428/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0154 - val_acc: 0.9968\n",
      "Epoch 429/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0156 - val_acc: 0.9968\n",
      "Epoch 430/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9981 - val_loss: 0.0158 - val_acc: 0.9969\n",
      "Epoch 431/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0158 - val_acc: 0.9968\n",
      "Epoch 432/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0106 - val_acc: 0.9976\n",
      "Epoch 433/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0128 - val_acc: 0.9970\n",
      "Epoch 434/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9980 - val_loss: 0.0145 - val_acc: 0.9968\n",
      "Epoch 435/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0108 - val_acc: 0.9976\n",
      "Epoch 436/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 437/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0146 - val_acc: 0.9969\n",
      "Epoch 438/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0149 - val_acc: 0.9969\n",
      "Epoch 439/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0111 - val_acc: 0.9974\n",
      "Epoch 440/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9968\n",
      "Epoch 441/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0174 - val_acc: 0.9964\n",
      "Epoch 442/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0147 - val_acc: 0.9968\n",
      "Epoch 443/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9967\n",
      "Epoch 444/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0252 - val_acc: 0.9949\n",
      "Epoch 445/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0143 - val_acc: 0.9966\n",
      "Epoch 446/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0143 - val_acc: 0.9969\n",
      "Epoch 447/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0150 - val_acc: 0.9968\n",
      "Epoch 448/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0137 - val_acc: 0.9970\n",
      "Epoch 449/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9969\n",
      "Epoch 450/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 451/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9980 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 452/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0159 - val_acc: 0.9963\n",
      "Epoch 453/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9968\n",
      "Epoch 454/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0155 - val_acc: 0.9969\n",
      "Epoch 455/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0119 - val_acc: 0.9970\n",
      "Epoch 456/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0102 - val_acc: 0.9977\n",
      "Epoch 457/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0158 - val_acc: 0.9969\n",
      "Epoch 458/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0144 - val_acc: 0.9970\n",
      "Epoch 459/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 460/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0105 - val_acc: 0.9976\n",
      "Epoch 461/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9968\n",
      "Epoch 462/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0159 - val_acc: 0.9969\n",
      "Epoch 463/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0136 - val_acc: 0.9952\n",
      "Epoch 464/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0164 - val_acc: 0.9969\n",
      "Epoch 465/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0156 - val_acc: 0.9966\n",
      "Epoch 466/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0105 - val_acc: 0.9976\n",
      "Epoch 467/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0154 - val_acc: 0.9970\n",
      "Epoch 468/700\n",
      " - 32s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.0104 - val_acc: 0.9976\n",
      "Epoch 469/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0138 - val_acc: 0.9960\n",
      "Epoch 470/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0156 - val_acc: 0.9968\n",
      "Epoch 471/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0106 - val_acc: 0.9976\n",
      "Epoch 472/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0136 - val_acc: 0.9967\n",
      "Epoch 473/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0152 - val_acc: 0.9969\n",
      "Epoch 474/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0103 - val_acc: 0.9975\n",
      "Epoch 475/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0104 - val_acc: 0.9977\n",
      "Epoch 476/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 477/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0149 - val_acc: 0.9969\n",
      "Epoch 478/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0147 - val_acc: 0.9968\n",
      "Epoch 479/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0127 - val_acc: 0.9972\n",
      "Epoch 480/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0164 - val_acc: 0.9968\n",
      "Epoch 481/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0155 - val_acc: 0.9970\n",
      "Epoch 482/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0144 - val_acc: 0.9971\n",
      "Epoch 483/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0153 - val_acc: 0.9967\n",
      "Epoch 484/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0166 - val_acc: 0.9961\n",
      "Epoch 485/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0156 - val_acc: 0.9967\n",
      "Epoch 486/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0143 - val_acc: 0.9970\n",
      "Epoch 487/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9968\n",
      "Epoch 488/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0150 - val_acc: 0.9968\n",
      "Epoch 489/700\n",
      " - 32s - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0109 - val_acc: 0.9973\n",
      "Epoch 490/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0108 - val_acc: 0.9975\n",
      "Epoch 491/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9969\n",
      "Epoch 492/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0132 - val_acc: 0.9971\n",
      "Epoch 493/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0121 - val_acc: 0.9971\n",
      "Epoch 494/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0153 - val_acc: 0.9969\n",
      "Epoch 495/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9969\n",
      "Epoch 496/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0142 - val_acc: 0.9970\n",
      "Epoch 497/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 498/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0167 - val_acc: 0.9967\n",
      "Epoch 499/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 500/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0153 - val_acc: 0.9969\n",
      "Epoch 501/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0133 - val_acc: 0.9971\n",
      "Epoch 502/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9969\n",
      "Epoch 503/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 504/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9976\n",
      "Epoch 505/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0134 - val_acc: 0.9971\n",
      "Epoch 506/700\n",
      " - 32s - loss: 0.0085 - acc: 0.9981 - val_loss: 0.0148 - val_acc: 0.9970\n",
      "Epoch 507/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0107 - val_acc: 0.9975\n",
      "Epoch 508/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0144 - val_acc: 0.9970\n",
      "Epoch 509/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 510/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0110 - val_acc: 0.9972\n",
      "Epoch 511/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0139 - val_acc: 0.9971\n",
      "Epoch 512/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0123 - val_acc: 0.9972\n",
      "Epoch 513/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0154 - val_acc: 0.9969\n",
      "Epoch 514/700\n",
      " - 32s - loss: 0.0084 - acc: 0.9981 - val_loss: 0.0149 - val_acc: 0.9969\n",
      "Epoch 515/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0100 - val_acc: 0.9976\n",
      "Epoch 516/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0129 - val_acc: 0.9971\n",
      "Epoch 517/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9969\n",
      "Epoch 518/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0116 - val_acc: 0.9973\n",
      "Epoch 519/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0146 - val_acc: 0.9970\n",
      "Epoch 520/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 521/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0119 - val_acc: 0.9967\n",
      "Epoch 522/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0106 - val_acc: 0.9974\n",
      "Epoch 523/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9970\n",
      "Epoch 524/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9969\n",
      "Epoch 525/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0157 - val_acc: 0.9968\n",
      "Epoch 526/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9982 - val_loss: 0.0146 - val_acc: 0.9970\n",
      "Epoch 527/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0103 - val_acc: 0.9974\n",
      "Epoch 528/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 529/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 530/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 531/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0107 - val_acc: 0.9975\n",
      "Epoch 532/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9981 - val_loss: 0.0141 - val_acc: 0.9970\n",
      "Epoch 533/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9964\n",
      "Epoch 534/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0102 - val_acc: 0.9977\n",
      "Epoch 535/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0142 - val_acc: 0.9968\n",
      "Epoch 536/700\n",
      " - 32s - loss: 0.0083 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9968\n",
      "Epoch 537/700\n",
      " - 33s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0159 - val_acc: 0.9967\n",
      "Epoch 538/700\n",
      " - 33s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0107 - val_acc: 0.9973\n",
      "Epoch 539/700\n",
      " - 33s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0096 - val_acc: 0.9978\n",
      "Epoch 540/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0158 - val_acc: 0.9969\n",
      "Epoch 541/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0148 - val_acc: 0.9970\n",
      "Epoch 542/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 543/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0139 - val_acc: 0.9969\n",
      "Epoch 544/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0140 - val_acc: 0.9968\n",
      "Epoch 545/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0102 - val_acc: 0.9977\n",
      "Epoch 546/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0098 - val_acc: 0.9978\n",
      "Epoch 547/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9970\n",
      "Epoch 548/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0143 - val_acc: 0.9967\n",
      "Epoch 549/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0144 - val_acc: 0.9969\n",
      "Epoch 550/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0122 - val_acc: 0.9972\n",
      "Epoch 551/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0123 - val_acc: 0.9971\n",
      "Epoch 552/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0157 - val_acc: 0.9969\n",
      "Epoch 553/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0096 - val_acc: 0.9978\n",
      "Epoch 554/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0107 - val_acc: 0.9974\n",
      "Epoch 555/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0101 - val_acc: 0.9976\n",
      "Epoch 556/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0133 - val_acc: 0.9968\n",
      "Epoch 557/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0131 - val_acc: 0.9971\n",
      "Epoch 558/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0115 - val_acc: 0.9970\n",
      "Epoch 559/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0176 - val_acc: 0.9963\n",
      "Epoch 560/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0150 - val_acc: 0.9969\n",
      "Epoch 561/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0131 - val_acc: 0.9970\n",
      "Epoch 562/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0101 - val_acc: 0.9976\n",
      "Epoch 563/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0117 - val_acc: 0.9971\n",
      "Epoch 564/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0150 - val_acc: 0.9970\n",
      "Epoch 565/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0156 - val_acc: 0.9956\n",
      "Epoch 566/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0102 - val_acc: 0.9977\n",
      "Epoch 567/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0099 - val_acc: 0.9976\n",
      "Epoch 568/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 569/700\n",
      " - 32s - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9967\n",
      "Epoch 570/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0158 - val_acc: 0.9969\n",
      "Epoch 571/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0153 - val_acc: 0.9969\n",
      "Epoch 572/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0128 - val_acc: 0.9971\n",
      "Epoch 573/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0159 - val_acc: 0.9969\n",
      "Epoch 574/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0142 - val_acc: 0.9969\n",
      "Epoch 575/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0165 - val_acc: 0.9968\n",
      "Epoch 576/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0197 - val_acc: 0.9960\n",
      "Epoch 577/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0151 - val_acc: 0.9970\n",
      "Epoch 578/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0153 - val_acc: 0.9970\n",
      "Epoch 579/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0135 - val_acc: 0.9968\n",
      "Epoch 580/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9969\n",
      "Epoch 581/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9970\n",
      "Epoch 582/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0118 - val_acc: 0.9970\n",
      "Epoch 583/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0140 - val_acc: 0.9972\n",
      "Epoch 584/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0114 - val_acc: 0.9972\n",
      "Epoch 585/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0098 - val_acc: 0.9977\n",
      "Epoch 586/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0150 - val_acc: 0.9971\n",
      "Epoch 587/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0137 - val_acc: 0.9971\n",
      "Epoch 588/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0142 - val_acc: 0.9963\n",
      "Epoch 589/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0138 - val_acc: 0.9972\n",
      "Epoch 590/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9970\n",
      "Epoch 591/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0154 - val_acc: 0.9969\n",
      "Epoch 592/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0157 - val_acc: 0.9970\n",
      "Epoch 593/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0118 - val_acc: 0.9973\n",
      "Epoch 594/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9969\n",
      "Epoch 595/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0140 - val_acc: 0.9972\n",
      "Epoch 596/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0101 - val_acc: 0.9976\n",
      "Epoch 597/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0144 - val_acc: 0.9969\n",
      "Epoch 598/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0148 - val_acc: 0.9967\n",
      "Epoch 599/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 600/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9970\n",
      "Epoch 601/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0102 - val_acc: 0.9977\n",
      "Epoch 602/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0151 - val_acc: 0.9969\n",
      "Epoch 603/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0154 - val_acc: 0.9969\n",
      "Epoch 604/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0130 - val_acc: 0.9972\n",
      "Epoch 605/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 606/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0144 - val_acc: 0.9971\n",
      "Epoch 607/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0110 - val_acc: 0.9972\n",
      "Epoch 608/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0146 - val_acc: 0.9971\n",
      "Epoch 609/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0130 - val_acc: 0.9970\n",
      "Epoch 610/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0165 - val_acc: 0.9969\n",
      "Epoch 611/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0190 - val_acc: 0.9923\n",
      "Epoch 612/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0164 - val_acc: 0.9970\n",
      "Epoch 613/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0118 - val_acc: 0.9971\n",
      "Epoch 614/700\n",
      " - 32s - loss: 0.0081 - acc: 0.9982 - val_loss: 0.0150 - val_acc: 0.9970\n",
      "Epoch 615/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0111 - val_acc: 0.9972\n",
      "Epoch 616/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0152 - val_acc: 0.9970\n",
      "Epoch 617/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0144 - val_acc: 0.9971\n",
      "Epoch 618/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0157 - val_acc: 0.9970\n",
      "Epoch 619/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0140 - val_acc: 0.9970\n",
      "Epoch 620/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0156 - val_acc: 0.9968\n",
      "Epoch 621/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0161 - val_acc: 0.9969\n",
      "Epoch 622/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0114 - val_acc: 0.9972\n",
      "Epoch 623/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0135 - val_acc: 0.9969\n",
      "Epoch 624/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0120 - val_acc: 0.9972\n",
      "Epoch 625/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9969\n",
      "Epoch 626/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0151 - val_acc: 0.9970\n",
      "Epoch 627/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9968\n",
      "Epoch 628/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0134 - val_acc: 0.9969\n",
      "Epoch 629/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0105 - val_acc: 0.9976\n",
      "Epoch 630/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0162 - val_acc: 0.9969\n",
      "Epoch 631/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0137 - val_acc: 0.9969\n",
      "Epoch 632/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0125 - val_acc: 0.9968\n",
      "Epoch 633/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0160 - val_acc: 0.9969\n",
      "Epoch 634/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0166 - val_acc: 0.9968\n",
      "Epoch 635/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0139 - val_acc: 0.9971\n",
      "Epoch 636/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0160 - val_acc: 0.9969\n",
      "Epoch 637/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0100 - val_acc: 0.9977\n",
      "Epoch 638/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0143 - val_acc: 0.9970\n",
      "Epoch 639/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0167 - val_acc: 0.9965\n",
      "Epoch 640/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0151 - val_acc: 0.9970\n",
      "Epoch 641/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0145 - val_acc: 0.9971\n",
      "Epoch 642/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0147 - val_acc: 0.9969\n",
      "Epoch 643/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0150 - val_acc: 0.9970\n",
      "Epoch 644/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0159 - val_acc: 0.9971\n",
      "Epoch 645/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0156 - val_acc: 0.9971\n",
      "Epoch 646/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0133 - val_acc: 0.9972\n",
      "Epoch 647/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0136 - val_acc: 0.9972\n",
      "Epoch 648/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0106 - val_acc: 0.9975\n",
      "Epoch 649/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0142 - val_acc: 0.9969\n",
      "Epoch 650/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0141 - val_acc: 0.9973\n",
      "Epoch 651/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0102 - val_acc: 0.9977\n",
      "Epoch 652/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0132 - val_acc: 0.9970\n",
      "Epoch 653/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0141 - val_acc: 0.9971\n",
      "Epoch 654/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0156 - val_acc: 0.9967\n",
      "Epoch 655/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9970\n",
      "Epoch 656/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0126 - val_acc: 0.9972\n",
      "Epoch 657/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0154 - val_acc: 0.9970\n",
      "Epoch 658/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0145 - val_acc: 0.9969\n",
      "Epoch 659/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0138 - val_acc: 0.9969\n",
      "Epoch 660/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0144 - val_acc: 0.9969\n",
      "Epoch 661/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0140 - val_acc: 0.9972\n",
      "Epoch 662/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0124 - val_acc: 0.9972\n",
      "Epoch 663/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0163 - val_acc: 0.9970\n",
      "Epoch 664/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0123 - val_acc: 0.9972\n",
      "Epoch 665/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0152 - val_acc: 0.9970\n",
      "Epoch 666/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0156 - val_acc: 0.9969\n",
      "Epoch 667/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0165 - val_acc: 0.9963\n",
      "Epoch 668/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0096 - val_acc: 0.9978\n",
      "Epoch 669/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0153 - val_acc: 0.9970\n",
      "Epoch 670/700\n",
      " - 32s - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0103 - val_acc: 0.9973\n",
      "Epoch 671/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0115 - val_acc: 0.9973\n",
      "Epoch 672/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0145 - val_acc: 0.9970\n",
      "Epoch 673/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0144 - val_acc: 0.9969\n",
      "Epoch 674/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0149 - val_acc: 0.9970\n",
      "Epoch 675/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0138 - val_acc: 0.9970\n",
      "Epoch 676/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0111 - val_acc: 0.9972\n",
      "Epoch 677/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0133 - val_acc: 0.9972\n",
      "Epoch 678/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0149 - val_acc: 0.9970\n",
      "Epoch 679/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0138 - val_acc: 0.9969\n",
      "Epoch 680/700\n",
      " - 32s - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0098 - val_acc: 0.9977\n",
      "Epoch 681/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0101 - val_acc: 0.9978\n",
      "Epoch 682/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 683/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0101 - val_acc: 0.9976\n",
      "Epoch 684/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0154 - val_acc: 0.9970\n",
      "Epoch 685/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0162 - val_acc: 0.9970\n",
      "Epoch 686/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0166 - val_acc: 0.9966\n",
      "Epoch 687/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9983 - val_loss: 0.0120 - val_acc: 0.9973\n",
      "Epoch 688/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0101 - val_acc: 0.9977\n",
      "Epoch 689/700\n",
      " - 32s - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0119 - val_acc: 0.9973\n",
      "Epoch 690/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0147 - val_acc: 0.9971\n",
      "Epoch 691/700\n",
      " - 32s - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0135 - val_acc: 0.9972\n",
      "Epoch 692/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0119 - val_acc: 0.9972\n",
      "Epoch 693/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0156 - val_acc: 0.9970\n",
      "Epoch 694/700\n",
      " - 32s - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0100 - val_acc: 0.9976\n",
      "Epoch 695/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0154 - val_acc: 0.9971\n",
      "Epoch 696/700\n",
      " - 32s - loss: 0.0078 - acc: 0.9982 - val_loss: 0.0144 - val_acc: 0.9972\n",
      "Epoch 697/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0133 - val_acc: 0.9973\n",
      "Epoch 698/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0121 - val_acc: 0.9972\n",
      "Epoch 699/700\n",
      " - 32s - loss: 0.0077 - acc: 0.9983 - val_loss: 0.0166 - val_acc: 0.9966\n",
      "Epoch 700/700\n",
      " - 32s - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0127 - val_acc: 0.9972\n",
      "Wall time: 6h 13min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9b5f6e470>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(model_id)\n",
    "model = createModel(**parameters)\n",
    "model.summary()\n",
    "model_checkpoint = ModelCheckpoint(NOTEBOOK_PATH + \"Models/%s/dnn({epoch}).h5\" % (model_id), monitor='val_loss')\n",
    "model.fit(x_train_res, y_train_res, validation_data=(x_val, y_val), \n",
    "          batch_size=parameters['batch_size'], \n",
    "          epochs=trainEpochs, \n",
    "          verbose=2, \n",
    "          callbacks=[csv_callback, model_checkpoint]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Xetrov/Desktop/SciFair20/Code/Loss Logs\\dnn8-sgd-autoencodershape (11-02-2019, 1148PM)\n"
     ]
    }
   ],
   "source": [
    "def most_recent_file(pattern):\n",
    "    return max(glob.iglob(pattern, recursive=True), key=os.path.getctime)\n",
    "\n",
    "logpath = most_recent_file(NOTEBOOK_PATH + \"Loss Logs/%s**\" % model_id)\n",
    "log_df = pd.read_csv(logpath)\n",
    "log_df['epoch'] += 1\n",
    "\n",
    "print(logpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       539.000000\n",
      "acc           0.998202\n",
      "loss          0.008102\n",
      "val_acc       0.997785\n",
      "val_loss      0.009566\n",
      "Name: 538, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = log_df[:]\n",
    "\n",
    "metric = 'loss'\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(x='epoch', y=metric, data=plot_df, label=metric)\n",
    "sns.lineplot(x='epoch', y='val_'+metric, data=plot_df, label='val_'+metric)\n",
    "plt.legend()\n",
    "\n",
    "minEpoch = plot_df.loc[plot_df.idxmin()[metric]]\n",
    "plt.plot((minEpoch['epoch']), (minEpoch[metric]), 'go', markersize=5)\n",
    "minEpoch = plot_df.loc[plot_df.idxmin()['val_'+metric]]\n",
    "plt.plot((minEpoch['epoch']), (minEpoch['val_'+metric]), 'ro', markersize=5)\n",
    "print(minEpoch)\n",
    "\n",
    "plt.xticks(list(range(0, plot_df['epoch'].max()+1, 25)))\n",
    "# plt.yticks(list(np.arange(0.0,0.4,0.05)))\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading...\")\n",
    "model = keras.models.load_model(NOTEBOOK_PATH + \"Models/%s/dnn(539).h5\" % model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Plotting...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Benign</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <td>111930</td>\n",
       "      <td>1242</td>\n",
       "      <td>113172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>12</td>\n",
       "      <td>452965</td>\n",
       "      <td>452977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>111942</td>\n",
       "      <td>454207</td>\n",
       "      <td>566149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual  Attack  Benign     All\n",
       "Pred                          \n",
       "Attack  111930    1242  113172\n",
       "Benign      12  452965  452977\n",
       "All     111942  454207  566149"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predicting...\")\n",
    "pred = model.predict(x_val)\n",
    "\n",
    "print(\"Plotting...\")\n",
    "pred_series = pd.Series(pred.round().astype('int').ravel(), name=\"Pred\").replace({0: 'Benign', 1: 'Attack'})\n",
    "y_series = pd.Series(y_val.to_numpy().ravel(), name=\"Actual\").replace({0: 'Benign', 1: 'Attack'})\n",
    "\n",
    "matrix = pd.crosstab(pred_series, y_series, margins=True)\n",
    "print(\"Done!\")\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9890641934509532\n",
      "Recall: 0.9997844808232833\n",
      "F1: 0.9943954449034276\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test).round().astype('int').ravel()\n",
    "y_test_npy = y_test.to_numpy().ravel()\n",
    "\n",
    "precision = precision_score(y_test_npy, pred)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "recall = recall_score(y_test_npy, pred)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "f1 = f1_score(y_test_npy, pred)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Benign</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <td>111335</td>\n",
       "      <td>1231</td>\n",
       "      <td>112566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benign</th>\n",
       "      <td>24</td>\n",
       "      <td>453559</td>\n",
       "      <td>453583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>111359</td>\n",
       "      <td>454790</td>\n",
       "      <td>566149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual  Attack  Benign     All\n",
       "Pred                          \n",
       "Attack  111335    1231  112566\n",
       "Benign      24  453559  453583\n",
       "All     111359  454790  566149"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_series = pd.Series(pred, name=\"Pred\").replace({0: 'Benign', 1: 'Attack'})\n",
    "y_series = pd.Series(y_test.to_numpy().ravel(), name=\"Actual\").replace({0: 'Benign', 1: 'Attack'})\n",
    "\n",
    "matrix = pd.crosstab(pred_series, y_series, margins=True)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log = open(NOTEBOOK_PATH + \"model_log.txt\", \"a\")\n",
    "\n",
    "model_log.write(\"\\n\" + model_id)\n",
    "model_log.write(\"\\n\\tF1 Micro: \" + str(f1_micro))\n",
    "model_log.write(\"\\n\\tF1 Macro: \" + str(f1_macro))\n",
    "\n",
    "model_log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
